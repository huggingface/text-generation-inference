name: "TensorRT-LLM C/C++/CUDA Test Suite"
on:
  push:
    branches:
      - 'main'
      - 'trtllm/ci'
    tags:
      - 'v*'
  pull_request:
    paths:
      - "backends/trtllm"
      - "server/**"
      - "proto/**"
      - "router/**"
      - "launcher/**"
      - "Cargo.lock"
      - "rust-toolchain.toml"
      - ".github/workflows/build_trtllm.yaml"
      - ".github/workflows/trtllm_tests.yaml"
    branches:
      - "main"

jobs:
  build-backend:
    permissions:
      contents: write
      packages: write
      id-token: write
    uses: ./.github/workflows/build_trtllm.yaml
    with:
      runs-on: aws-highmemory-64-plus-priv
    secrets: inherit

  run-tests:
    needs: build-backend
    concurrency:
      group: ${{ github.workflow }}-${{ github.job }}-trtllm-${{ github.head_ref || github.run_id }}
      cancel-in-progress: true
    runs-on:
      group: aws-g6-12xl-plus-priv-cache
    container:
      image: ${{ needs.build-backend.outputs.docker_image }}
      credentials:
        username: ${{ secrets.REGISTRY_USERNAME }}
        password: ${{ secrets.REGISTRY_PASSWORD }}
      options: --gpus all --shm-size=8g

    steps:
      - name: Run C++/CUDA tests
        run: /usr/local/tgi/bin/tgi_trtllm_backend_tests