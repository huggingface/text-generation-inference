name: Build TensorRT-LLM
on:
  workflow_call:
    inputs:
      runs-on:
        type: string
        description: "Which instance type to use to run the workflow"
        required: true

    outputs:
      docker_image:
        description: "Reference to the Docker Image build by this workflow"
        value: ${{ jobs.build-and-push.outputs.docker_image }}
      label:
        description: "Label generated for this build"
        value: ${{ jobs.build-and-push.outputs.label }}

jobs:
  build-and-push:
    permissions:
      contents: read # Required to check out repository.
      id-token: write # Required to authenticate via OIDC.

    concurrency:
      group: ${{ github.workflow }}-${{ github.job }}-build-and-push-${{ github.head_ref || github.run_id }}
    outputs:
      docker_image: ${{ steps.final.outputs.docker_image }}
      label: ${{ steps.final.outputs.label }}
    runs-on:
      group: ${{ inputs.runs-on }}
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}

      - name: Inject slug/short variables
        uses: rlespinasse/github-slug-action@v4.4.1

      - name: Extract TensorRT-LLM version
        run: |
          echo "TENSORRT_LLM_VERSION=$(grep -oP '([a-z,0-9]{40})' $GITHUB_WORKSPACE/backends/trtllm/cmake/trtllm.cmake)" >> $GITHUB_ENV
          echo "TensorRT-LLM version: ${{ env.TENSORRT_LLM_VERSION }}"

      - name: Set LABEL
        run: |
          echo "LABEL=trtllm" >> $GITHUB_ENV

      - name: "Configure AWS Credentials"
        id: aws-creds
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: us-east-1
          role-to-assume: ${{ secrets.AWS_ROLE_GITHUB_TGI_TEST }}
          role-duration-seconds: 7200
          output-credentials: true

      - name: Initialize Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          install: true
          buildkitd-config: /tmp/buildkitd.toml

      - name: Login to internal Container Registry
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.REGISTRY_USERNAME }}
          password: ${{ secrets.REGISTRY_PASSWORD }}
          registry: registry.internal.huggingface.tech

      - name: Login to GitHub Container Registry
        if: github.event_name != 'pull_request'
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # If pull request
      - name: Extract metadata (tags, labels) for Docker
        if: ${{ github.event_name == 'pull_request' }}
        id: meta-pr
        uses: docker/metadata-action@v5
        with:
          images: |
            registry.internal.huggingface.tech/api-inference/community/text-generation-inference/tensorrt-llm
          tags: |
            type=raw,value=sha-${{ env.GITHUB_SHA_SHORT }}-${{ env.LABEL }}

      # If main, release or tag
      - name: Extract metadata (tags, labels) for Docker
        if: ${{ github.event_name != 'pull_request' }}
        id: meta
        uses: docker/metadata-action@v5
        with:
          flavor: |
            latest=auto
          images: |
            registry.internal.huggingface.tech/api-inference/community/text-generation-inference/tensorrt-llm
          #            ghcr.io/huggingface/text-generation-inference
          tags: |
            type=semver,pattern={{version}}${{ env.LABEL }}
            type=semver,pattern={{major}}.{{minor}}${{ env.LABEL }}
            type=raw,value=latest${{ env.LABEL }},enable=${{ github.ref == format('refs/heads/{0}', github.event.repository.default_branch) }}
            type=raw,value=sha-${{ env.GITHUB_SHA_SHORT }}-${{ env.LABEL }}

      - name: Build and push Docker image
        id: build-and-push
        uses: docker/build-push-action@v6
        with:
          context: .
          file: Dockerfile_trtllm
          target: ci-runtime
          push: true
          load: true
          tags: ${{ steps.meta.outputs.tags || steps.meta-pr.outputs.tags }}
          platforms: 'linux/amd64'
          build-args: |
            build_type=dev
            is_gha_build=TRUE
            aws_access_key_id=${{ steps.aws-creds.outputs.aws-access-key-id }}
            aws_secret_access_key=${{ steps.aws-creds.outputs.aws-secret-access-key }}
            aws_session_token=${{ steps.aws-creds.outputs.aws-session-token }}
            sccache_bucket=${{ secrets.AWS_S3_BUCKET_GITHUB_TGI_TEST }}
            sccache_s3_key_prefix=trtllm-${{ env.TENSORRT_LLM_VERSION }}
            sccache_region=us-east-1
          cache-from: type=s3,region=us-east-1,bucket=ci-docker-buildx-cache,name=text-generation-inference-cache-${{ env.LABEL }},mode=min,access_key_id=${{ secrets.S3_CI_DOCKER_BUILDX_CACHE_ACCESS_KEY_ID }},secret_access_key=${{ secrets.S3_CI_DOCKER_BUILDX_CACHE_SECRET_ACCESS_KEY }},mode=min
          cache-to: type=s3,region=us-east-1,bucket=ci-docker-buildx-cache,name=text-generation-inference-cache-${{ env.LABEL }},mode=min,access_key_id=${{ secrets.S3_CI_DOCKER_BUILDX_CACHE_ACCESS_KEY_ID }},secret_access_key=${{ secrets.S3_CI_DOCKER_BUILDX_CACHE_SECRET_ACCESS_KEY }},mode=min
      - name: Final
        id: final
        run: |
          echo "docker_image=registry.internal.huggingface.tech/api-inference/community/text-generation-inference/tensorrt-llm:sha-${{ env.GITHUB_SHA_SHORT }}-${{ env.LABEL }}" >> "$GITHUB_OUTPUT"
          echo "label=${{ env.LABEL }}" >> "$GITHUB_OUTPUT"

  run-tests:
    needs: build-and-push
    concurrency:
      group: ${{ github.workflow }}-${{ github.job }}-trtllm-${{ github.head_ref || github.run_id }}
      cancel-in-progress: true
    runs-on:
      group: aws-g6-12xl-plus-priv-cache
    container:
      image: ${{ needs.build-and-push.outputs.docker_image }}
      credentials:
        username: ${{ secrets.REGISTRY_USERNAME }}
        password: ${{ secrets.REGISTRY_PASSWORD }}
      options: --gpus all --shm-size=8g

    steps:
      - name: whoami
        run: |
          echo "Container: ${{ needs.build-and-push.outputs.docker_image }}"

      - name: List binaries
        run: ls -alh /usr/local/tgi

      - name: Run C++/CUDA tests
        run: /usr/local/tgi/bin/tgi_trtllm_backend_tests

